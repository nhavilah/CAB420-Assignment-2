{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels import api as sm\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard import notebook\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import scipy.io\n",
    "import numpy\n",
    "import cv2\n",
    "\n",
    "from sklearn.svm import SVC,NuSVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(30607, 140, 54)\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.path.abspath(os.getcwd())+\"/256_ObjectCategories/\"\n",
    "#add the arrays that we can use for training and testing\n",
    "main_x = []\n",
    "main_y = []\n",
    "prev_file = [\"\"]\n",
    "current_index = 0\n",
    "for subdir, dirs, files in os.walk(root_dir):\n",
    "    for dir in dirs:\n",
    "        current_dir = os.path.join(root_dir) + dir\n",
    "        after = str(current_dir.split(\".\",1)[1])\n",
    "        for file in os.listdir(current_dir):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.endswith(\".jpg\"):\n",
    "                current_file = cv2.imread(os.path.join(current_dir,filename),0)\n",
    "                current_file = cv2.resize(current_file, dsize=(54, 140), interpolation=cv2.INTER_CUBIC)\n",
    "                main_x.append(current_file)\n",
    "                main_y.append(current_index)\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "        current_index = current_index+1\n",
    "    break\n",
    "images_x = np.array(main_x)\n",
    "images_y = np.array(main_y)\n",
    "print(np.shape(images_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(images_y.dtype)\n",
    "fig = plt.figure(figsize=[10,10])\n",
    "for i in range(100):\n",
    "    ax = fig.add_subplot(10,10,i+1)\n",
    "    ax.imshow(x_train[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_x_train, x_test, temp_y_train, y_test = train_test_split(images_x,images_y,test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(temp_x_train,temp_y_train,test_size=0.2,random_state=42)\n",
    "print(numpy.shape(x_train))\n",
    "print(numpy.shape(x_test))\n",
    "print(numpy.shape(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, roc_curve,auc\n",
    "def eval_model(model):\n",
    "    #predict Test Accuracy\n",
    "    test_scores = model.evaluate(test,test_y,verbose=2)\n",
    "    print(\"Testing Loss: \"+str(test_scores[0]))\n",
    "    print(\"Testing Accuracy: \"+str(test_scores[1]))\n",
    "\n",
    "    #display the ROC Curve\n",
    "    classes = numpy.unique(train_y)\n",
    "    fig = plt.figure(figsize=[10,10])\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    for i in range(10):\n",
    "        fpr,tpr,_=roc_curve(test_y,pred[:,i],pos_label=classes[i])\n",
    "        auc_score = auc(fpr,tpr)\n",
    "        ax.plot(fpr,tpr,label='%s: %0.2f' % (classes[i],auc_score))\n",
    "    ax.legend()\n",
    "\n",
    "    #confusion matrix\n",
    "    fig = plt.figure(figsize=[10,10])\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    pred = model.predict(test)\n",
    "    indexes = tf.argmax(pred,axis=1)\n",
    "    cm = confusion_matrix(test_y,indexes)\n",
    "    c = ConfusionMatrixDisplay(cm,display_labels=range(10))\n",
    "    c.plot(ax=ax)\n",
    "    ax.set_title('Testing Performance')\n",
    "    eval_model(new_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(30607, 7560)\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.path.abspath(os.getcwd())+\"/256_ObjectCategories/\"\n",
    "#add the arrays that we can use for training and testing\n",
    "main_x = []\n",
    "main_y = []\n",
    "prev_file = [\"\"]\n",
    "current_index = 0\n",
    "for subdir, dirs, files in os.walk(root_dir):\n",
    "    for dir in dirs:\n",
    "        current_dir = os.path.join(root_dir) + dir\n",
    "        after = str(current_dir.split(\".\",1)[1])\n",
    "        for file in os.listdir(current_dir):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.endswith(\".jpg\"):\n",
    "                current_file = cv2.imread(os.path.join(current_dir,filename),0)\n",
    "                current_file = cv2.resize(current_file, dsize=(54, 140), interpolation=cv2.INTER_CUBIC)\n",
    "                main_x.append(current_file.flatten())\n",
    "                main_y.append(current_index)\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "        current_index = current_index+1\n",
    "    break\n",
    "images_x = np.array(main_x)\n",
    "images_y = np.array(main_y)\n",
    "print(np.shape(images_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(24791, 140, 54)\n(3061, 140, 54)\n(2755, 140, 54)\n0\n1\n"
     ]
    }
   ],
   "source": [
    "temp_x_train, x_test, temp_y_train, y_test = train_test_split(images_x,images_y,test_size=0.1, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(temp_x_train,temp_y_train,test_size=0.1,random_state=42)\n",
    "print(numpy.shape(x_train))\n",
    "print(numpy.shape(x_test))\n",
    "print(numpy.shape(x_val))\n",
    "print(images_y[0])\n",
    "print(images_y[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[0])\n",
    "print(y_train[98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SVC(class_weight='balanced')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#setup the SVM\n",
    "#grid search cross validation has already been imported ready for hyperparameter tuning\n",
    "svm = SVC(class_weight='balanced')\n",
    "#add some stuff for some shitty hyperparameter tuning here. You guys figure out the smarter way to do it. I belive the smarter way is using the range functionality to narrow down the range of values but you will need to investigate\n",
    "#param_grid = [\n",
    "#    {'C':[0.1,1,10,100],'kernel':['linear']},\n",
    "#    {'C':[0.1,1,10,100],'gamma':[0.1,0.01,0.001],'kernel':['rbf']},\n",
    "#    {'C':[0.1,1,10,100],'degree':[3,4,5],'kernel':['poly']},\n",
    "#]\n",
    "#grid_search = GridSearchCV(svm, param_grid)\n",
    "#grid_search.fit(x_train,y_train)\n",
    "#grid_search.cv_results_\n",
    "#best_system = np.argmin(grid_search.cv_results_['rank_test_score'])\n",
    "#params = grid_search.cv_results_['params'][best_system]\n",
    "#print(params)\n",
    "#svm = SVC().set_params(**params)\n",
    "svm.fit(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"CNN\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nimg (InputLayer)             [(None, 140, 54, 1)]      0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 140, 54, 8)        80        \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 140, 54, 8)        584       \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 140, 54, 8)        32        \n_________________________________________________________________\nactivation_3 (Activation)    (None, 140, 54, 8)        0         \n_________________________________________________________________\nspatial_dropout2d_3 (Spatial (None, 140, 54, 8)        0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 70, 27, 8)         0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 70, 27, 8)         584       \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 70, 27, 8)         584       \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 70, 27, 8)         32        \n_________________________________________________________________\nactivation_4 (Activation)    (None, 70, 27, 8)         0         \n_________________________________________________________________\nspatial_dropout2d_4 (Spatial (None, 70, 27, 8)         0         \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 35, 13, 8)         0         \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 35, 13, 8)         584       \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 35, 13, 8)         584       \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 35, 13, 8)         32        \n_________________________________________________________________\nactivation_5 (Activation)    (None, 35, 13, 8)         0         \n_________________________________________________________________\nspatial_dropout2d_5 (Spatial (None, 35, 13, 8)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 3640)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 256)               932096    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 64)                16448     \n_________________________________________________________________\ndense_5 (Dense)              (None, 257)               16705     \n=================================================================\nTotal params: 968,345\nTrainable params: 968,297\nNon-trainable params: 48\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build a DCNN real quick\n",
    "num_epochs = 50\n",
    "\n",
    "def build_model(num_classes,output_activation=None):\n",
    "    inputs = keras.Input(shape=(140,54,1),name='img')\n",
    "\n",
    "    x = layers.Conv2D(filters=8, kernel_size=(3,3),padding='same',activation='relu')(inputs)\n",
    "    x = layers.Conv2D(filters=8,kernel_size=(3,3),padding='same',activation=None)(x)\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.SpatialDropout2D(0.2)(x)\n",
    "\n",
    "    x = layers.MaxPool2D(pool_size=(2,2))(x)\n",
    "\n",
    "    x = layers.Conv2D(filters=8, kernel_size=(3,3),padding='same',activation='relu')(x)\n",
    "    x = layers.Conv2D(filters=8,kernel_size=(3,3),padding='same',activation=None)(x)\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.SpatialDropout2D(0.2)(x)\n",
    "\n",
    "    x = layers.MaxPool2D(pool_size=(2,2))(x)\n",
    "\n",
    "    x = layers.Conv2D(filters=8, kernel_size=(3,3),padding='same',activation='relu')(x)\n",
    "    x = layers.Conv2D(filters=8,kernel_size=(3,3),padding='same',activation=None)(x)\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.SpatialDropout2D(0.2)(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Dense(256,activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(64,activation='relu')(x)\n",
    "    outputs = layers.Dense(num_classes,activation=output_activation)(x)\n",
    "\n",
    "    model_cnn = keras.Model(inputs=inputs, outputs=outputs, name='CNN')\n",
    "\n",
    "    return model_cnn\n",
    "\n",
    "model_cnn = build_model(257)\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "InvalidArgumentError",
     "evalue": " Received a label value of 256 which is outside the valid range of [0, 256).  Label values: 158 199 128 154 237 255 33 189 233 243 231 89 231 209 167 0 13 158 201 238 57 172 242 47 253 153 23 81 237 65 99 183 161 102 120 138 182 256 116 144 237 56 104 105 36 214 64 174 174 58 34 40 194 151 177 194 126 144 71 126 135 195 247 71 81 160 92 136 157 65 108 39 67 52 6 143 128 12 42 170 49 154 58 31 153 138 49 35 12 10 68 213 117 168 144 211 95 9 221 108 129 147 46 184 13 79 192 104 79 147 155 198 175 176 256 211 138 39 143 95 191 37 256 94 231 243 119 234 144 163 200 163 199 95 155 183 15 199 91 95 136 232 110 4 91 136 68 54 188 127 71 143 67 66 256 121 144 52 1 144 4 217 96 231 154 254 2 36 84 159 180 168 45 208 9 254 234 39 54 244 18 95 135 39 66 161 218 91 66 142 237 224 252 236 206 240 96 209 209 144 157 157 49 132 8 147 256 235 213 243 90 220 146 115 180 10 48 172 151 214 89 213 21 24 252 12 38 169 180 256 125 191 140 140 147 90 60 1 192 111 176 196 159 144 135 119 25 231 95 231 31 105 185 243 217 146\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-8-25c79b9a810e>:4) ]] [Op:__inference_train_function_1730]\n\nFunction call stack:\ntrain_function\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-25c79b9a810e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m metrics=['accuracy'])\n\u001b[1;32m----> 4\u001b[1;33m history = model_cnn.fit(x_train,y_train,\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  Received a label value of 256 which is outside the valid range of [0, 256).  Label values: 158 199 128 154 237 255 33 189 233 243 231 89 231 209 167 0 13 158 201 238 57 172 242 47 253 153 23 81 237 65 99 183 161 102 120 138 182 256 116 144 237 56 104 105 36 214 64 174 174 58 34 40 194 151 177 194 126 144 71 126 135 195 247 71 81 160 92 136 157 65 108 39 67 52 6 143 128 12 42 170 49 154 58 31 153 138 49 35 12 10 68 213 117 168 144 211 95 9 221 108 129 147 46 184 13 79 192 104 79 147 155 198 175 176 256 211 138 39 143 95 191 37 256 94 231 243 119 234 144 163 200 163 199 95 155 183 15 199 91 95 136 232 110 4 91 136 68 54 188 127 71 143 67 66 256 121 144 52 1 144 4 217 96 231 154 254 2 36 84 159 180 168 45 208 9 254 234 39 54 244 18 95 135 39 66 161 218 91 66 142 237 224 252 236 206 240 96 209 209 144 157 157 49 132 8 147 256 235 213 243 90 220 146 115 180 10 48 172 151 214 89 213 21 24 252 12 38 169 180 256 125 191 140 140 147 90 60 1 192 111 176 196 159 144 135 119 25 231 95 231 31 105 185 243 217 146\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-8-25c79b9a810e>:4) ]] [Op:__inference_train_function_1730]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model_cnn.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "optimizer=keras.optimizers.Adam(),\n",
    "metrics=['accuracy'])\n",
    "history = model_cnn.fit(x_train,y_train,\n",
    "batch_size=256,\n",
    "epochs=num_epochs,\n",
    "validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}